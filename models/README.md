#模型

# AlexNet
### 一.网络框架
![AlexNet1](jpg/AlexNet1.png)
8个学习层：5个卷积层+3个全连接层（部分卷积层后有最大池化）

![AlexNet2](jpg/AlexNet2.png)

$$
H_{out}是输出size,H_{in}输入size,p是补半圈0，2p是补一圈0，D是卷积核的size,S是步长
$$
$$ 
H_{out} = \left\lfloor \frac{H_{in} + 2P - D}{S} + 1 \right\rfloor
$$

#### 第一个卷积层
![ALexNet3](jpg/AlexNet3.png)
![ALexNet4](jpg/AlexNet4.png)
- 卷积运算: 原始数据 227 x 227 x 3的图像。卷积核尺寸 11 x 11 x 3 (高，宽，深)，步长是4，每次卷积都生成新的像素96(2个48)的卷积核。卷积核在移动过程中生成(227-11)/4+1=55个像素。则卷积后的像素层为55 x 55 x 96(2组 55 x 55 x 48)，每组在应该独立的GPU上运算。
- 激活函数: 激活函数 ReLU 处理，生成激活像素层，尺寸 55 x 55 x 96。
- 池化: 池化窗口 3 x 3，步长 2，则池化后像素的尺寸为（55-3）/2+1。
反向传播时，每个卷积核对应一个偏差值。即第一层的96个卷积核对应上层输入的96个偏差值。

