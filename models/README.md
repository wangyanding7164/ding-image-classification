#模型

# AlexNet
### 一.网络框架
![AlexNet1](jpg/AlexNet1.png)
8个学习层：5个卷积层+3个全连接层（部分卷积层后有最大池化）

![AlexNet2](jpg/AlexNet2.png)

- 卷积后的矩阵尺寸大小计算公式： N = (W - F + 2P)/S +1
① 输入图片大小W x W
② Filter大小F x F 卷积核大小
③ stride步长S
④ padding的像素数P

#### 第一个卷积层
![ALexNet3](jpg/AlexNet3.png)
![ALexNet4](jpg/AlexNet4.png)
Conv1:  
kernels:48*2=96  
kernel_size:11  
paddding:[1,2]  
stride:4  
input_size:[224,224,3]  
output_size:[55,55,96]  
- Conv1 卷积运算 原始图像224 x 224 x 3(高，宽，深)  卷积核大小 11 * 11 ,卷积核个数48(两块GPU并行,所以48*2=96),stride步长4,（224-11+(1+2)）/4+1  
Maxpool1:  
kernel_size:3
paddinng:0
stride:2
input_size:[55,55,96]
output_size:[27,27,96]
- Maxpools 池化层计算 输入图像层 55 x 55 x 96 池化核大小 3 x 3,输出图像层(27 x 27 x 96)          （55-3）/2+1=27  
#### 第二个卷积层
![AlexNet5](jpg/AlexNet5.png)
![AlexNet6](jpg/AlexNet6.png)
Conv2:  
kernels:128*2=256  
kernel_size:5  
stride:1  
paddding:[2,2]  
input_size:[27,27,96]  
output_size:[27,27,256]  
- Conv2 输入图像层大小27 x 27 x 96 卷积核大小 5 x 5,卷积核个数128,步长1,(27-5+2+2)/1+1=27  
Maxpool2:  
kernel_size:3
paddinng:0
stride:2
input_size:[27,27,256]
output_size:[13,13,256]
- Maxpool2 池化层计算 输入图像层 27 x 27 x 256 池化核大小 3 x 3,输出图像层(13 x 13 x 256)          （27-3）/2+1=13  
#### 第三个卷积层
![AlexNet7](jpg/AlexNet7.png)
![AlexNet8](jpg/AlexNet8.png)
Conv3:  
kernels:192*2=384  
kernel_size:3  
stride:1  
paddding:[1,1]  
input_size:[13,13,256]  
output_size:[13,13,384]  
- Conv3 输入图像层大小 13 x 13 x 256 卷积核大小 3 x 3,卷积核个数384,步长1,(13-3+1+1)/1+1=13  
#### 第四个卷积层
![AlexNet9](jpg/AlexNet9.png)
![AlexNet10](jpg/AlexNet10.png)
Conv4:  
kernels:192*2=384  
kernel_size:3  
stride:1  
paddding:[1,1]  
input_size:[13,13,384]  
output_size:[13,13,384]  
- Conv4 输入图像层大小 13 x 13 x 384 卷积核大小 3 x 3,卷积核个数384,步长1,(13-3+1+1)/1+1=13  
#### 第五个卷积层
![AlexNet11](jpg/AlexNet11.png)
![AlexNet12](jpg/AlexNet12.png)
Conv5:  
kernels:128*2=256 
kernel_size:3  
stride:1  
paddding:[1,1]  
input_size:[13,13,384]  
output_size:[13,13,256]
- Conv5 输入图像层大小 13 x 13 x 384 卷积核大小 3 x 3,卷积核个数256,步长1,(13-3+1+1)/1+1=13  
Maxpool3:  
kernel_size:3
paddinng:0
stride:2
input_size:[13,13,256]
output_size:[13,13,256]  
- Maxpool3 输入图像层 13 x 13 x 256 池化核大小 3 x 3,输出图像层(6 x 6 x 256)          （13-3）/2+1=6

 # VGGNet

## 一、VGG的特点

![1](jpg\vgg1.jpg)

#### 1、结构简洁

​	VGG由5层卷积层、3层全连接层、softmax输出层构成，曾与曾之间使用maxpooling(最大池化层)分开，所有隐藏单元都采用ReLU函数。

​	下图是来自论文《Very Deep Convolutional Networks for Large-Scale Image Recognition》（基于甚深层卷积网络的大规模图像识别）的VGG网络结构，正是在这篇论文中提出了VGG，如下图： 

![0](jpg\VGG.jpeg)

在这篇论文中分别使用了A、A-LRN、B、C、D、E这6种网络结构进行测试，这6种网络结构相似，都是由5层卷积层、3层全连接层组成，其中区别在于每个卷积层的子层数量不同，从A至E依次增加（子层数量从1到4），总的网络深度从11层到19层

以网络结构D（VGG16）为例:

1、输入224x224x3的图片，经64个3x3的卷积核作两次卷积+ReLU，卷积后的尺寸变为224x224x64

2、作max pooling（最大化池化），池化单元尺寸为2x2（效果为图像尺寸减半），池化后的尺寸变为112x112x64

3、经128个3x3的卷积核作两次卷积+ReLU，尺寸变为112x112x128

4、作2x2的max pooling池化，尺寸变为56x56x128

5、经256个3x3的卷积核作三次卷积+ReLU，尺寸变为56x56x256

6、作2x2的max pooling池化，尺寸变为28x28x256

7、经512个3x3的卷积核作三次卷积+ReLU，尺寸变为28x28x512

8、作2x2的max pooling池化，尺寸变为14x14x512

9、经512个3x3的卷积核作三次卷积+ReLU，尺寸变为14x14x512

10、作2x2的max pooling池化，尺寸变为7x7x512

11、与两层1x1x4096，一层1x1x1000进行全连接+ReLU（共三层）

12、通过softmax输出1000个预测结果



#### 2、小卷积核和多卷积子层

​	VGG使用多个较小卷积核（3x3）的卷积层代替一个卷积核较大的卷积层，一方面可以减少参数，另一方面相当于进行了更多的非线性映射，可以增加网络的拟合/表达能力。

​	小卷积核是VGG的一个重要特点，虽然VGG是在模仿AlexNet的网络结构，但没有采用AlexNet中比较大的卷积核尺寸（如7x7），而是通过降低卷积核的大小（3x3），增加卷积子层数来达到同样的性能（VGG：从1到4卷积子层，AlexNet：1子层）。

​	VGG的作者认为两个3x3的卷积堆叠获得的感受野大小，相当一个5x5的卷积；而3个3x3卷积的堆叠获取到的感受野相当于一个7x7的卷积。这样可以增加非线性映射，也能很好地减少参数（例如7x7的参数为49个，而3个3x3的参数为27）

​	**使用更小的卷积核是当前在保证网络精度的情况下，减少参数的趋势之一，在VGG16中，使用了3个3\*3卷积核来代替7\*7卷积核，使用了2个3\*3卷积核来代替5\*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。**

![vgg2](jpg\vgg2.png)



##### 1、感受野

###### 	1.什么是感受野？

​		**感受野是指一个神经元能看到的输入区域**，给一个直观的例子：**这是3个3×3卷积核对于7× 7 卷积的代替演示图**



![VGG](jpg\VGG.gif)

###### 		2.感受野的计算公式

###### 		**F(i) = (F(i+1)-1) x Stride + Ksize**

​		F(i) 为第i层感受野, Stride为第i层步距, Ksize为卷积核大小或者池化核大小

​	![3](jpg\vgg3.png)



感受野计算是从最后一层往前推，看能在原图上“看”到多大范围。
Feature map: F=1
Conv3x3(3): F=(1-1)/1+3=3
Conv3x3(2): F=(3-1)/1+3=5
Conv3x3(1): F=(5-1)/1+3=7
Conv7x7(1): F=(1-1)/1+7=7
由此可知用3x3卷积核叠3层后与7x7卷积核感受野相同。



# GoogLeNet

## 要点

1.引入Inception结构

2.使用1x1的卷积核进行降维以及映射处理

3.添加两个辅助分类器帮助训练

4.丢弃全连接层，使用平均池化层（大大减少模型参数）

## 什么是GoogLeNet

一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，深度指网络层次数量、宽度指神经元数量。但这种方式存在以下问题：

（1）参数太多，如果训练数据集有限，很容易产生过拟合；

（2）网络越大、参数越多，计算复杂度越大，难以应用；

（3）网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型。

那么，GoogLeNet是如何进一步提升性能的呢？有没有一种方法既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，就如人类的大脑是可以看做是神经元的重复堆积，因此，GoogLeNet团队提出了Inception网络结构，就是构造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。

## 什么是Inception

Inception历经了V1、V2、V3、V4等多个版本的发展，不断趋于完善，下面简单进行初始版和v1版本

## 一、Inception V1

通过设计一个稀疏网络结构，但是能够产生稠密的数据，既能增加神经网络表现，又能保证计算资源的使用效率。谷歌提出了最原始Inception的基本结构：
![Googlenet1](jpg\Googlenet1.jpg)



该结构将CNN中常用的卷积（1x1，3x3，5x5）、池化操作（3x3）堆叠在一起（卷积、池化后的尺寸相同，将通道相加），一方面增加了网络的宽度，另一方面也增加了网络对尺度的适应性。

网络卷积层中的网络能够提取输入的每一个细节信息，同时5x5的滤波器也能够覆盖大部分接受层的的输入。还可以进行一个池化操作，以减少空间大小，降低过度拟合。在这些层之上，在每一个卷积层后都要做一个**ReLU**操作，以增加网络的非线性特征。

然而这个Inception原始版本，所有的卷积核都在上一层的所有输出上来做，而那个5x5的卷积核所需的计算量就太大了，造成了特征图的厚度很大，为了避免这种情况，在3x3前、5x5前、max pooling后分别加上了1x1的卷积核，以起到了降低特征图厚度的作用，这也就形成了Inception v1的网络结构，如下图所示： 

![AlexNet2](jpg\AlexNet2.png)

**1x1的卷积核有什么用呢？**

1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）。比如，上一层的输出为100x100x128，经过具有256个通道的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256，其中，卷积层的参数为128x5x5x256= 819200。而假如上一层输出先经过具有32个通道的1x1卷积层，再经过具有256个输出的5x5卷积层，那么输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256= 204800，大约减少了4倍。

## GoogLeNet的结构

![GooGLeNet](jpg\GooGLeNet.jpg)

GoogLeNet的网络结构图细节如下： 

![GoogLeNet0](jpg\GoogLeNet0.jpg)

**0、输入**

原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。

**1、第一层（卷积层）**

使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作

经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作

**2、第二层（卷积层）**

使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作

经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作

**3a、第三层（Inception 3a层）**

分为四个分支，采用不同尺度的卷积核来进行处理

（1）64个1x1的卷积核，然后RuLU，输出28x28x64

（2）96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128

（3）16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32

（4）pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32。

将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256

**3b、第三层（Inception 3b层）**

（1）128个1x1的卷积核，然后RuLU，输出28x28x128

（2）128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192

（3）32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96

（4）pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64。

将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480



第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复。

# ResNet

## ResNet网络是什么

Resnet在cnn图像方面有着非常突出的表现，它利用 **shortcut 短路连接**，解决了深度网络中***模型退化\***的问题。相比普通网络每两层/三层之间增加了短路机制，通过*残差学习*使深层的网络发挥出作用。

## 网络结构

![resnet13](jpg\resnet13.png)

![resnet12](jpg\resnet12.png)

## ResNet网络的亮点

1.超深的网络结构（突破1000层）

2.提出residual模块

3.使用barch Normalization（丢弃Dropout）

### 为什么要用residual（残差）

在ResNet提出之前，所有的神经网络都是通过**卷积层和池化层的叠加**组成的。
人们认为卷积层和池化层的层数越多，获取到的图片特征信息越全，学习效果也就越好。但是在实际的试验中发现，随着卷积层和池化层的叠加，**不但没有出现**学习效果越来越好的情况，反而出现

#### 两种问题：

##### 1.梯度消失和梯度爆炸

梯度**消失**：若每一层的误差梯度小于1，反向传播时，网络越深，梯度越趋近于0
梯度**爆炸**：若每一层的误差梯度大于1，反向传播时，网络越深，梯度越来越大

##### 2.退化问题

随着层数的增加，预测效果反而**越来越差**。如下图所示 

![ResNet](jpg\ResNet.png)

此图就是用卷积层加池化层堆叠到20层和56层，训练的误差反而更深的更高。

由于神经网络在反向传播过程中通过链式法则不断地反向传播更新梯度，而当网络层数加深时，梯度在传播过程中会逐渐消失也就说我们所说的梯度弥散。这将导致无法对前面网络层的权重进行有效的调整，网络层数越深，训练误差越高，导致训练和测试效果变差，这一现象称为**退化**

##### 3.解决方法

为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为残差网络 (ResNets)。ResNet论文提出了 residual结构（残差结构）来减轻退化问题，下图是使用residual结构的卷积网络，可以看到随着网络的不断加深，效果并没有变差，而是变的更好了。（虚线是train error，实线是test error）

![ResNet2](jpg\ResNet2.png)

#### 残差学习

残差即观测值H(x)与预测值x之间的差

深度网络的退化问题至少说明深度网络不容易训练。但是我们考虑这样一个事实：现在你有一个浅层网络，你想通过向上堆积新层来建立深层网络，一个极端情况是这些增加的层什么也不学习，仅仅**复制**浅层网络的特征，即这样新层是恒等映射（Identity mapping）。在这种情况下，深层网络应该至少和浅层网络性能一样，那么退化问题就得到了解决。



传统的CNN网络如上图所示，这是一个普通的、两层的卷积+激活。经过两层卷积+一个激活，我们假定它输出为H(x)。与传统的网络结构相比，ResNet增加了**短路连接(shortcut connection)或称为跳跃连接(skip connection)** ，如下图所示：



![ResNet4](jpg\ResNet4.png)

![resnet5](jpg\resnet5.png)

从数学角度分析一下：

![resnet6](jpg\resnet6.png)

F(x) := H(x)−x 残差 如果是0就是最坏的情况

其中![\mathrm{x}_{\mathrm{l}}](https://latex.csdn.net/eq?%5Cmathrm%7Bx%7D_%7B%5Cmathrm%7Bl%7D%7D)和![\mathrm{x}_{\mathrm{l}+1}](https://latex.csdn.net/eq?%5Cmathrm%7Bx%7D_%7B%5Cmathrm%7Bl%7D&plus;1%7D)分别表示的是第 ![l](https://latex.csdn.net/eq?l)个残差单元的输入和输出，注意每个残差单元一般包含多层结构。![F](https://latex.csdn.net/eq?F)是残差函数，表示学习到的残差，而 ![h(x_l)=x_l](https://latex.csdn.net/eq?h%28x_l%29%3Dx_l)表示**恒等映射**，![f](https://latex.csdn.net/eq?f)是ReLU激活函数。基于上式，我们求得从浅层![l](https://latex.csdn.net/eq?l) 到深层![L](https://latex.csdn.net/eq?L)的学习特征为：

![resnet8](jpg\resnet8.png)

##### 简单理解：

**核心思想就一句话：让网络学习“差多少”，而不是学习“是什么”。**

我们可以把它拆解成三个问题来理解：

###### 1. 它想解决什么问题？（“退化问题”）

- 想象一下，盖楼。理论上，100层的楼应该比10层的楼功能更强（能表示更复杂的东西）。
- 但在深度学习里，人们发现，有时候网络层数越深（比如100层），效果反而比浅的网络（比如10层）还要差。这就叫“退化问题”。
- 这很奇怪，因为最差的情况，那新增的90层如果啥也不干，直接把10层的结果传上去，效果也应该和10层的楼一样好才对啊！但传统的网络连这点都做不到。

###### 2. 它怎么解决的？（“短路连接”）

- ResNet（残差网络）想出了一个超级聪明又简单的办法：**抄近道**。
- 看图的**右边**，那条从`x`直接弯到`+`号的线，就是“近道”，也叫“短路连接”或“跳跃连接”。
- **没有近道（左图）**：输入`x`必须经过两层复杂的卷积运算，才能得到输出`H(x)`。路很长，容易“迷路”（梯度消失/爆炸），学偏了。
- **有近道（右图）**：网络现在不用从头学习最终的输出`H(x)`了，它只需要学习**输出和输入之间的那个“差值”**，也就是`F(x) = H(x) - x`。
- 最终的输出就是 `F(x) + x`（在`+`号那里相加）。

###### 3. 为什么这样就能解决问题？（“恒等映射”）

- 这个“抄近道”的设计有一个天大的好处：**它保证了最差情况下的性能**。

- 对于新加的那些层，最差的情况就是它们啥也没学会，此时我们希望它们的输出不影响原有结果。

- 在残差块里，如果新加的层啥也没学会，那么`F(x)`就应该是0。这样，输出就变成了 `0 + x = x`。

- 看，**输出直接等于输入**！这个“直接等于”的操作，就叫做“恒等映射”。

- 这意味着，即使新加的层是废柴，整个网络block的性能也至少不会比浅层的网络差。这就彻底解决了“退化问题”，让训练成百上千层的超深网络成为可能。

  

###### **总结一下：**

**残差学习**就是通过一条**短路连接**，让深度网络中的每一个小模块（残差块）不去学习一个完整的输出，而是去学习**输出和输入之间的残差（差值）**。这样保证了网络在最差情况下也能实现**恒等映射**，从而解决了深度网络的退化问题

### ResNet中两种不同的ResNet block

ResNet block有两种，一种左侧两层的BasicBlock结构，一种是右侧三层的bottleneck结构，即将两个3x3的卷积层替换为1x1+3x3+1x1，它通过 1x1conv来巧妙地缩减或扩张feature map维度，从而使得我们的 3x3conv的filters数目不受上一层输入的影响，它的输出也不会影响到下一层。中间的卷积层首先在一个降维1x1卷积层下减少了计算，然后在另一个1x1的卷积层下做了还原。既保持了模型精度又减少了网络参数和计算量，节省了计算时间。

![ResNet9](jpg\ResNet9.png)

![ResNet7](jpg\ResNet7.png)



#### 简单理解：

两种核心结构：BasicBlock vs Bottleneck

图里展示了两种实现“抄近道”的基本单元（也叫残差块）：

上图**左侧：BasicBlock（基础块）**

**结构**：像 `[3x3卷积] -> [3x3卷积]`这样简单的两层结构。

**工作方式**：输入 `x`兵分两路。

**主路**：`x`经过两层卷积运算，得到一个结果，我们称之为 `F(x)`（残差）。

**近道**：`x`直接“抄近道”跑过去，什么也不做。

**汇合**：最后把主路的结果 `F(x)`和近道来的 `x`直接加起来，得到最终输出：`H(x) = F(x) + x`。



上图**右侧：Bottleneck（瓶颈块）**

**为什么需要它**：当网络非常深、非常宽（通道数很多）时，用两个3x3卷积计算量太大、太慢。Bottleneck结构就是为了**减少计算量、节省时间**而设计的“高配版”基础块。

**结构**：像 `[1x1卷积] -> [3x3卷积] -> [1x1卷积]`这样的三层结构，像一个沙漏，所以叫“瓶颈”。

**工作方式（降维->卷积->升维）**：

**第一个1x1卷积**：**降维**。就像把一条很宽的马路先收窄，减少车流量（减少通道数），这样后续操作计算量就小了。

**中间的3x3卷积**：在“窄路”上进行核心的卷积操作，因为路变窄了，所以这个最耗时的步骤变得高效了。

**第二个1x1卷积**：**升维**。把道路再恢复到原来的宽度（恢复通道数），以便和“近道”来的 `x`相加。

**它更高效**：虽然多了一层，但通过先降维再升维的巧妙设计，总的计算量反而比直接做两个3x3卷积要少得多。



#####  **最重要的原则：主路和近道的输出必须“形状相同”**

图里反复强调了一点：**主分支与shortcut的输出特征矩阵shape必须相同**。

**为什么？** 因为最后要把它们俩 (`F(x)`和 `x`) **直接相加（`+`）**。就像数学题一样，只有两个维度和数量完全一样的矩阵才能相加。

**如果形状不同怎么办？** 图中也给出了解决方案：

**方法一（不推荐）**：对 `x`进行**全零填充**，硬把它的尺寸撑大。但这效率不高，效果也不好。

**方法二（推荐）**：对 `x`也进行一个简单的变换（**投影捷径**），比如用一个 **1x1的卷积** 来处理一下近道信号 `x`，调整它的维度和尺寸，让它能和大路来的 `F(x)`完美相加。这个1x1卷积本身就起到了降维或升维的作用。

------

### 总结

**要解决什么问题？** 网络太深不好训练，效果会变差（退化问题）。

**怎么解决的？** 引入“抄近道”（捷径连接）思想，让网络不再学习完整的输出，而是学习**输出和输入之间的“残差”或“差值”** (`F(x) = H(x) - x`)。

**怎么实现的？** 通过两种基本结构：

**BasicBlock**：简单直接，两层3x3卷积。适用于较浅的网络。

**Bottleneck**：先压缩（1x1卷积）、再处理（3x3卷积）、最后扩展（1x1卷积）。计算高效，用于构建非常深的网络（如ResNet-50, 101, 1

**关键注意事项**：无论用什么结构，主路算出来的结果必须和“近道”传来的原始输入在**维度上完全匹配**，这样才能相加。不匹配时，就用1x1卷积来调整。



引用CSDN博主「大龙唉」的原创文章：https://blog.csdn.net/weixin_44001371/article/details/134192776



Batch Normalization

1.目的：使我们的一批（batch）数据所对应的数据的feature map（所对应的特征矩阵）每一个通道所对应的维度满足均值为0，方差为1的分布规律。



## **Batch Normalization**

![batch_normalization1](jpg\batch_normalization1.png)

![ ](jpg\batch_normalization2.png)

![ ](jpg\batch_normalzation3.png)

文章来自博主“太阳花的小绿豆”

详细链接：https://blog.csdn.net/qq_37541097/article/details/104434557

和李宏毅老师讲解：https://www.bilibili.com/video/av9770302?p=10

# Batch Normalization（BN）原理详解

## 1. 目的

解决深度神经网络训练过程中的**内部协变量偏移（Internal Covariate Shift）**问题。即网络中间层的输入分布随着前层参数更新而发生变化，导致训练困难。

## 2. 方法

对每个批次（batch）的特征进行标准化，使其满足**均值为0、方差为1**的分布。

## 3. 数学公式

### 3.1 计算均值和方差

对每个特征维度（channel）计算：

**均值计算：**

```
μ_B = (1/m) * Σ(x_i)   (i从1到m)
```

**方差计算：**

```
σ²_B = (1/m) * Σ(x_i - μ_B)²   (i从1到m)
```

其中：

- m为批次大小（batch size）
- xi为第i个样本的特征值
- μB为当前批次的均值
- σB2为当前批次的方差

### 3.2 标准化处理

**标准化公式：**

```
x̂_i = (x_i - μ_B) / √(σ²_B + ε)
```

其中：

- ϵ是一个很小的常数（通常为10−5），用于防止分母为零

### 3.3 缩放和平移（引入可学习参数）

**最终输出：**

```
y_i = γ * x̂_i + β
```

其中：

- γ为缩放参数（scale parameter）
- β为平移参数（shift parameter）
- 这两个参数在训练过程中通过反向传播学习得到

## 4. 训练与推理差异

| 阶段       | 统计量使用方式                                               |
| ---------- | ------------------------------------------------------------ |
| **训练时** | 使用当前批次的统计量（均值μB、方差σB2）                      |
| **推理时** | 使用训练过程中通过**移动平均（moving average）**记录的全局统计量 |

### 移动平均更新公式：

**均值更新：**

```
μ_running = μ_running × momentum + μ_B × (1 - momentum)
```

**方差更新：**

```
σ²_running = σ²_running × momentum + σ²_B × (1 - momentum)
```

其中 momentum 通常设置为 0.9（对应 PyTorch 中的默认值），即：

```
momentum = 0.9
1 - momentum = 0.1
```

# 迁移学习

优势：

能够快速的训练出一个理想的结果

当数据集较小时也能训练出理想的效果

注：使用别人与训练模型参数时，要注意别人的预处理方式

![qianyistudy](jpg\qianyistudy.png)

对于浅层卷积层所学习的一些角点信息/纹理信息等通用信息，在其他网络中仍然适用。所以将学习好的网络的浅层网络的一些参数迁移到新的网络当中。这样新的网络就也拥有了识别底层通用特征的能力。这样新的网络就能更快速的学习新的数据集的高维特征。

## 常见的迁移学习方法

1.载入权重后训练所有参数

2.载入权重后只训练最后几层参数

3.载入权重后在原网络基础上在添加一层全连接层，仅训练最后一个全连接层

2.3更快，1.效果更好
